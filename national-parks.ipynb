{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Historical Visitation Numbers of U.S. National Parks\n",
    "https://github.com/carl-schick-ds/national-parks\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will analyze the historical visitation counts for each U.S. National Park and attempt to answer the following questions: \n",
    " - How does the age of a national park impact annual visitation?\n",
    " - How does the area-size of a national park impact annual visitation?\n",
    " - Are visitation numbers impacted when a site receives an official national park designation?\n",
    " - Does the location of a national park impact annual visitation?\n",
    " - How does the weather impact monthly visitation?\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "The first step of the project is to collect the data from various sources on the internet.  \n",
    "\n",
    "Data is currently collected from two main sources...\n",
    " - The National Park Services' Integrated Resourcde Management Applications (IRMA) Portal\n",
    "   - List of official national park unit codes\n",
    "   - Monthly visitation counts for each national park\n",
    " - Wikipedia\n",
    "   - Location (lat/long), date established, and gross area acres for each national park\n",
    "\n",
    "Web scraping is performed using the [Beautfiul Soup](https://www.crummy.com/software/BeautifulSoup/) library.  \n",
    "Fuzzy matching logic for park names is performed using the [The Fuzz (formerly Fuzzy Wuzzy)](https://github.com/seatgeek/thefuzz) library.\n",
    "\n",
    "**_Data collection will rebuild/refresh the CSV files used for the remainder of the notebook._**  \n",
    "**_Data collection can be toggled on/off with the REFRESH_DATA boolean flag._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFRESH_DATA = False\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if REFRESH_DATA:\n",
    "    # pip install thefuzz\n",
    "\n",
    "    from bs4 import BeautifulSoup\n",
    "    from thefuzz import fuzz\n",
    "    from thefuzz import process\n",
    "    import requests\n",
    "    import time\n",
    "    import re\n",
    "    user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'\n",
    "    headers = {'User-Agent': user_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DATA:\n",
    "    from requests.adapters import HTTPAdapter\n",
    "    from requests.packages.urllib3.util.retry import Retry\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    http = requests.Session()\n",
    "    http.mount(\"https://\", adapter)\n",
    "    http.mount(\"http://\", adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DATA:\n",
    "\n",
    "    park_units_url = 'https://irmaservices.nps.gov/v2/rest/unit/designations'\n",
    "    park_units_namespace = {'root': 'NRPC.IrmaServices.Rest.Unit'}\n",
    "    park_unit_exceptions = {'DENG':'DENA', 'GAAG':'GAAR', 'GLBG':'GLBA', 'GRDG':'GRSA', 'KATG':'KATM', 'LACG':'LACL', 'WRSG':'WRST'}\n",
    "    \n",
    "    national_parks = {}\n",
    "    r = http.get(park_units_url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, \"xml\")\n",
    "    # print(soup)\n",
    "\n",
    "    for unit_designation in soup.find_all('UnitDesignation'):\n",
    "        if unit_designation.find(\"Code\").text == 'NP':\n",
    "            units = unit_designation.find(\"Units\")\n",
    "            for value in units.find_all('Value'):\n",
    "                raw_code = value.find(\"Code\").text\n",
    "                name = value.find(\"Name\").text\n",
    "                code = raw_code if raw_code not in park_unit_exceptions.keys() else park_unit_exceptions[raw_code]\n",
    "                national_parks[code] = name\n",
    "\n",
    "    # Manually add New River Gorge, if it hasn't been added yet\n",
    "    if 'NERI' not in national_parks.keys():\n",
    "        national_parks['NERI'] = 'New River Gorge'\n",
    "\n",
    "    # print(national_parks)\n",
    "    park_units_df = pd.DataFrame.from_dict(national_parks, orient='index', columns=['name'])\n",
    "    park_units_df.index.name = 'code'\n",
    "    park_units_df.sort_index(inplace=True)\n",
    "    park_units_df.to_csv('national_park_units.csv')\n",
    "    # print(park_units_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DATA:\n",
    "\n",
    "    # park_visits_homepage = 'https://irma.nps.gov/STATS/'\n",
    "    park_visits_domain = 'https://irma.nps.gov'\n",
    "    park_visits_url = '/STATS/SSRSReports/Park%20Specific%20Reports/Recreation%20Visitors%20By%20Month%20(1979%20-%20Last%20Calendar%20Year)'\n",
    "    park_visits_qs = '?Park='\n",
    "    park_visits_df = pd.DataFrame()\n",
    "    target_table_min = 10\n",
    "\n",
    "    print('Processing:', end=\" \")\n",
    "    for park_code in park_units_df.index:\n",
    "        print(park_code, end=\", \")\n",
    "        park_visits_request = park_visits_domain + park_visits_url + park_visits_qs + park_code\n",
    "        r = http.get(park_visits_request, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(r.text, \"html\")\n",
    "        park_visits_iframe = soup.find('iframe').attrs['src']\n",
    "\n",
    "        park_visits_request = park_visits_domain + park_visits_iframe\n",
    "        r = http.get(park_visits_request, headers=headers, timeout=5)\n",
    "\n",
    "        dfs = pd.read_html(r.text, match=\"Year\", skiprows=1)\n",
    "        for df in dfs:\n",
    "            if len(df) > target_table_min: one_park_df = df\n",
    "        \n",
    "        new_header = one_park_df.iloc[0] #grab the first row for the header\n",
    "        one_park_df = one_park_df[1:] #take the data less the header row\n",
    "        one_park_df.columns = new_header #set the header row as the df header\n",
    "    \n",
    "        one_park_df = one_park_df.fillna(0)\n",
    "        if 'Total' in one_park_df.columns:\n",
    "            one_park_df.drop('Total', axis=1, inplace=True)\n",
    "\n",
    "        one_park_df.set_index('Year', inplace=True)\n",
    "        one_park_srs = one_park_df.stack()\n",
    "\n",
    "        park_visits_df[park_code] = one_park_srs\n",
    "\n",
    "    park_visits_df = park_visits_df.fillna(0)\n",
    "    park_visits_df.index.names = ['Year', 'Month']\n",
    "    park_visits_df.to_csv('national_park_visits.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_DATA:\n",
    "\n",
    "    park_data_url = 'https://en.wikipedia.org/wiki/List_of_national_parks_of_the_United_States'\n",
    "    \n",
    "    r = http.get(park_data_url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, \"xml\")\n",
    "    # print(soup)\n",
    "\n",
    "    dfs = pd.read_html(r.text, match=\"Date established as park\")\n",
    "    park_data_df = dfs[0]\n",
    "\n",
    "    # Strip years and footnotes from columns\n",
    "    for column_name in park_data_df.columns.values:\n",
    "        if '(' in column_name or '[' in column_name:\n",
    "            new_column_name = re.sub(\"\\(.*?\\)\",\"\", column_name)\n",
    "            new_column_name = re.sub(\"\\[.*?\\]\",\"\", new_column_name)\n",
    "            new_column_name = new_column_name.strip()\n",
    "            park_data_df.rename(columns={column_name: new_column_name}, inplace=True)\n",
    " \n",
    "    # Rename some columns and drop unneeded columns\n",
    "    park_data_df.rename(columns={'Date established as park': 'Established', 'Area': 'Acres'}, inplace=True)\n",
    "    park_data_df.drop(columns=['Image', 'Recreation visitors'], inplace=True)\n",
    "\n",
    "    # Remove asterisks from the park names\n",
    "    park_data_df['Name'] = park_data_df['Name'].str.replace('*', '').str.strip()\n",
    "\n",
    "    # Add each park's unit code\n",
    "    # We will need fuzzy string matching logic to match the name from Wikipedia with the name from NPS\n",
    "    nps_names = park_units_df['name'].to_list()\n",
    "    # print(nps_names)\n",
    "    for index, row in park_data_df.iterrows():\n",
    "        # print(park_data_df.loc[index,'Name'])\n",
    "        matching_name, matching_ratio = process.extractOne(park_data_df.loc[index,'Name'], nps_names)\n",
    "        # print(matching_name, matching_ratio)\n",
    "        # print(park_units_df[park_units_df['name'] == matching_name].index.tolist()[0])\n",
    "        park_data_df.loc[index,'Code'] = park_units_df[park_units_df['name'] == matching_name].index.tolist()[0]\n",
    "    \n",
    "    # Parse state from Location into new column; update Location to only lat/long coordinates\n",
    "    park_data_df['State'] = park_data_df['Location'].apply(lambda x: re.split('[^a-zA-Z\\s\\.]', x)[0].replace('.mw', ''))\n",
    "    park_data_df['Location'] = park_data_df['Location'].apply(lambda x: x.rpartition('/')[2].strip())\n",
    "\n",
    "    # Remove footnotes from established dates\n",
    "    park_data_df['Established'] = park_data_df['Established'].apply(lambda x: re.sub('\\[\\d*?\\]', '', x).strip())\n",
    "\n",
    "    # Clean Acres column\n",
    "    park_data_df['Acres'] = park_data_df['Acres'].apply(lambda x: re.split('[^\\d\\,\\.]', x)[0])\n",
    "\n",
    "    park_data_df = park_data_df[['Code', 'Name', 'State', 'Location', 'Established', 'Acres', 'Description']]\n",
    "\n",
    "    park_data_df.set_index('Code', inplace=True)\n",
    "    park_data_df.to_csv('national_park_data.csv')\n",
    "    # print(park_data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV files\n",
    "park_visits_df = pd.read_csv('national_park_visits.csv', index_col=[0,1])\n",
    "park_data_df = pd.read_csv('national_park_data.csv', index_col=0)\n",
    "# print(park_visits_df.head())\n",
    "# print(park_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 516 entries, (2021, 'JAN') to (1979, 'DEC')\n",
      "Data columns (total 63 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   ACAD    516 non-null    int64\n",
      " 1   ARCH    516 non-null    int64\n",
      " 2   BADL    516 non-null    int64\n",
      " 3   BIBE    516 non-null    int64\n",
      " 4   BISC    516 non-null    int64\n",
      " 5   BLCA    516 non-null    int64\n",
      " 6   BRCA    516 non-null    int64\n",
      " 7   CANY    516 non-null    int64\n",
      " 8   CARE    516 non-null    int64\n",
      " 9   CAVE    516 non-null    int64\n",
      " 10  CHIS    516 non-null    int64\n",
      " 11  CONG    516 non-null    int64\n",
      " 12  CRLA    516 non-null    int64\n",
      " 13  CUVA    516 non-null    int64\n",
      " 14  DENA    516 non-null    int64\n",
      " 15  DEVA    516 non-null    int64\n",
      " 16  DRTO    516 non-null    int64\n",
      " 17  EVER    516 non-null    int64\n",
      " 18  GAAR    516 non-null    int64\n",
      " 19  GLAC    516 non-null    int64\n",
      " 20  GLBA    516 non-null    int64\n",
      " 21  GRBA    516 non-null    int64\n",
      " 22  GRCA    516 non-null    int64\n",
      " 23  GRSA    516 non-null    int64\n",
      " 24  GRSM    516 non-null    int64\n",
      " 25  GRTE    516 non-null    int64\n",
      " 26  GUMO    516 non-null    int64\n",
      " 27  HALE    516 non-null    int64\n",
      " 28  HAVO    516 non-null    int64\n",
      " 29  HOSP    516 non-null    int64\n",
      " 30  INDU    516 non-null    int64\n",
      " 31  ISRO    516 non-null    int64\n",
      " 32  JEFF    516 non-null    int64\n",
      " 33  JOTR    516 non-null    int64\n",
      " 34  KATM    516 non-null    int64\n",
      " 35  KEFJ    516 non-null    int64\n",
      " 36  KICA    516 non-null    int64\n",
      " 37  KOVA    516 non-null    int64\n",
      " 38  LACL    516 non-null    int64\n",
      " 39  LAVO    516 non-null    int64\n",
      " 40  MACA    516 non-null    int64\n",
      " 41  MEVE    516 non-null    int64\n",
      " 42  MORA    516 non-null    int64\n",
      " 43  NERI    516 non-null    int64\n",
      " 44  NOCA    516 non-null    int64\n",
      " 45  NPSA    516 non-null    int64\n",
      " 46  OLYM    516 non-null    int64\n",
      " 47  PEFO    516 non-null    int64\n",
      " 48  PINN    516 non-null    int64\n",
      " 49  REDW    516 non-null    int64\n",
      " 50  ROMO    516 non-null    int64\n",
      " 51  SAGU    516 non-null    int64\n",
      " 52  SEQU    516 non-null    int64\n",
      " 53  SHEN    516 non-null    int64\n",
      " 54  THRO    516 non-null    int64\n",
      " 55  VIIS    516 non-null    int64\n",
      " 56  VOYA    516 non-null    int64\n",
      " 57  WHSA    516 non-null    int64\n",
      " 58  WICA    516 non-null    int64\n",
      " 59  WRST    516 non-null    int64\n",
      " 60  YELL    516 non-null    int64\n",
      " 61  YOSE    516 non-null    int64\n",
      " 62  ZION    516 non-null    int64\n",
      "dtypes: int64(63)\n",
      "memory usage: 256.9+ KB\n",
      "None\n",
      "               ACAD           ARCH           BADL          BIBE  \\\n",
      "count  5.160000e+02     516.000000     516.000000    516.000000   \n",
      "mean   2.446680e+05   71077.255814   85095.112403  25960.786822   \n",
      "std    2.445558e+05   56611.242004   92718.782505  13868.342425   \n",
      "min    0.000000e+00       0.000000       0.000000      0.000000   \n",
      "25%    2.578675e+04   18142.750000   14861.750000  16071.750000   \n",
      "50%    1.681770e+05   60858.000000   34333.000000  22926.000000   \n",
      "75%    4.276718e+05  110528.750000  156195.250000  32162.250000   \n",
      "max    1.045060e+06  238499.000000  363803.000000  89915.000000   \n",
      "\n",
      "                BISC          BLCA           BRCA           CANY  \\\n",
      "count     516.000000    516.000000     516.000000     516.000000   \n",
      "mean    37061.377907  19982.308140   95795.104651   32634.800388   \n",
      "std     17617.603004  19031.142684   91194.811297   27566.274413   \n",
      "min         0.000000      0.000000       0.000000       0.000000   \n",
      "25%     25091.000000   4220.250000   21654.000000    6985.750000   \n",
      "50%     35865.500000  12470.500000   72637.500000   27540.500000   \n",
      "75%     48183.500000  31387.500000  149393.500000   52394.500000   \n",
      "max    113151.000000  82583.000000  430020.000000  134778.000000   \n",
      "\n",
      "                CARE           CAVE  ...           SHEN           THRO  \\\n",
      "count     516.000000     516.000000  ...     516.000000     516.000000   \n",
      "mean    53051.478682   45554.697674  ...  126536.932171   43644.472868   \n",
      "std     42727.535041   29953.242323  ...   91008.840581   46381.380496   \n",
      "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
      "25%     12499.250000   24477.250000  ...   39102.500000    3690.000000   \n",
      "50%     49600.000000   37066.000000  ...  119970.500000   23148.000000   \n",
      "75%     80243.250000   56586.000000  ...  182693.250000   76903.000000   \n",
      "max    221206.000000  152161.000000  ...  420713.000000  176271.000000   \n",
      "\n",
      "                VIIS          VOYA           WHSA           WICA  \\\n",
      "count     516.000000    516.000000     516.000000     516.000000   \n",
      "mean    47178.131783  18523.406977   44756.707364   51213.430233   \n",
      "std     22667.478686  17640.668054   17115.595260   49625.545914   \n",
      "min         0.000000      0.000000       0.000000       0.000000   \n",
      "25%     30904.750000   3009.250000   30191.750000   13350.000000   \n",
      "50%     47941.000000  10944.000000   43809.000000   26617.000000   \n",
      "75%     61434.500000  29182.750000   58089.750000   78422.000000   \n",
      "max    119783.000000  70657.000000  112288.000000  238482.000000   \n",
      "\n",
      "               WRST          YELL           YOSE           ZION  \n",
      "count    516.000000  5.160000e+02     516.000000     516.000000  \n",
      "mean    3674.052326  2.549721e+05  285928.240310  212382.244186  \n",
      "std     6020.379383  2.961020e+05  180239.361928  141774.011293  \n",
      "min        0.000000  0.000000e+00       0.000000       0.000000  \n",
      "25%       94.500000  2.451350e+04  125163.000000   75870.250000  \n",
      "50%      520.000000  5.562750e+04  244417.500000  206974.500000  \n",
      "75%     5329.500000  4.905540e+05  429865.250000  319116.500000  \n",
      "max    28929.000000  1.081062e+06  780728.000000  675799.000000  \n",
      "\n",
      "[8 rows x 63 columns]\n",
      "ACAD    0\n",
      "ARCH    0\n",
      "BADL    0\n",
      "BIBE    0\n",
      "BISC    0\n",
      "       ..\n",
      "WICA    0\n",
      "WRST    0\n",
      "YELL    0\n",
      "YOSE    0\n",
      "ZION    0\n",
      "Length: 63, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quick review of Park Visits data\n",
    "print(park_visits_df.info())\n",
    "print(park_visits_df.describe())\n",
    "print(park_visits_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63 entries, ACAD to ZION\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Name         63 non-null     object\n",
      " 1   State        63 non-null     object\n",
      " 2   Location     63 non-null     object\n",
      " 3   Established  63 non-null     object\n",
      " 4   Acres        63 non-null     object\n",
      " 5   Description  63 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 3.4+ KB\n",
      "None\n",
      "Name           0\n",
      "State          0\n",
      "Location       0\n",
      "Established    0\n",
      "Acres          0\n",
      "Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Quick review of Park Data data\n",
    "print(park_data_df.info())\n",
    "print(park_data_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63 entries, ACAD to ZION\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   Name         63 non-null     object        \n",
      " 1   State        63 non-null     object        \n",
      " 2   Location     63 non-null     object        \n",
      " 3   Established  63 non-null     datetime64[ns]\n",
      " 4   Acres        63 non-null     float64       \n",
      " 5   Description  63 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 3.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean up Park Data by converting Established to datetime and Acres to float\n",
    "park_data_df['Established'] = pd.to_datetime(park_data_df['Established'])\n",
    "park_data_df['Acres'] = park_data_df['Acres'].str.replace(',', '').astype(float)\n",
    "park_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Established</th>\n",
       "      <th>Acres</th>\n",
       "      <th>Description</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACAD</th>\n",
       "      <td>Acadia</td>\n",
       "      <td>Maine</td>\n",
       "      <td>﻿44.35°N 68.21°W</td>\n",
       "      <td>1919-02-26</td>\n",
       "      <td>49076.63</td>\n",
       "      <td>Covering most of Mount Desert Island and other...</td>\n",
       "      <td>2787366</td>\n",
       "      <td>2779666</td>\n",
       "      <td>2997972</td>\n",
       "      <td>3572114</td>\n",
       "      <td>...</td>\n",
       "      <td>2431052</td>\n",
       "      <td>2254922</td>\n",
       "      <td>2563129</td>\n",
       "      <td>2811184</td>\n",
       "      <td>3303393</td>\n",
       "      <td>3509271</td>\n",
       "      <td>3537575</td>\n",
       "      <td>3437286</td>\n",
       "      <td>2669034</td>\n",
       "      <td>4054767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPSA</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>﻿14.25°S 170.68°W</td>\n",
       "      <td>1988-10-31</td>\n",
       "      <td>8256.67</td>\n",
       "      <td>The southernmost national park is on three Sam...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10440</td>\n",
       "      <td>17919</td>\n",
       "      <td>13953</td>\n",
       "      <td>13892</td>\n",
       "      <td>28892</td>\n",
       "      <td>69468</td>\n",
       "      <td>28626</td>\n",
       "      <td>60006</td>\n",
       "      <td>4819</td>\n",
       "      <td>7284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARCH</th>\n",
       "      <td>Arches</td>\n",
       "      <td>Utah</td>\n",
       "      <td>﻿38.68°N 109.57°W</td>\n",
       "      <td>1971-11-12</td>\n",
       "      <td>76678.98</td>\n",
       "      <td>This site features more than 2,000 natural san...</td>\n",
       "      <td>269840</td>\n",
       "      <td>290519</td>\n",
       "      <td>326508</td>\n",
       "      <td>339415</td>\n",
       "      <td>...</td>\n",
       "      <td>1070577</td>\n",
       "      <td>1082866</td>\n",
       "      <td>1284767</td>\n",
       "      <td>1399247</td>\n",
       "      <td>1585718</td>\n",
       "      <td>1539028</td>\n",
       "      <td>1663557</td>\n",
       "      <td>1659702</td>\n",
       "      <td>1238083</td>\n",
       "      <td>1750341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BADL</th>\n",
       "      <td>Badlands</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>﻿43.75°N 102.50°W</td>\n",
       "      <td>1978-11-10</td>\n",
       "      <td>242755.94</td>\n",
       "      <td>The Badlands are a collection of buttes, pinna...</td>\n",
       "      <td>858000</td>\n",
       "      <td>952652</td>\n",
       "      <td>1175952</td>\n",
       "      <td>1030484</td>\n",
       "      <td>...</td>\n",
       "      <td>883406</td>\n",
       "      <td>892372</td>\n",
       "      <td>868094</td>\n",
       "      <td>989354</td>\n",
       "      <td>996263</td>\n",
       "      <td>1054325</td>\n",
       "      <td>1008942</td>\n",
       "      <td>970998</td>\n",
       "      <td>916932</td>\n",
       "      <td>1228481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIBE</th>\n",
       "      <td>Big Bend</td>\n",
       "      <td>Texas</td>\n",
       "      <td>﻿29.25°N 103.25°W</td>\n",
       "      <td>1944-06-12</td>\n",
       "      <td>801163.21</td>\n",
       "      <td>Named for the prominent bend in the Rio Grande...</td>\n",
       "      <td>282941</td>\n",
       "      <td>174008</td>\n",
       "      <td>167332</td>\n",
       "      <td>180144</td>\n",
       "      <td>...</td>\n",
       "      <td>292055</td>\n",
       "      <td>316953</td>\n",
       "      <td>314102</td>\n",
       "      <td>381747</td>\n",
       "      <td>388290</td>\n",
       "      <td>440276</td>\n",
       "      <td>440091</td>\n",
       "      <td>463832</td>\n",
       "      <td>393907</td>\n",
       "      <td>524126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name           State           Location Established  \\\n",
       "Code                                                                  \n",
       "ACAD          Acadia           Maine   ﻿44.35°N 68.21°W  1919-02-26   \n",
       "NPSA  American Samoa  American Samoa  ﻿14.25°S 170.68°W  1988-10-31   \n",
       "ARCH          Arches            Utah  ﻿38.68°N 109.57°W  1971-11-12   \n",
       "BADL        Badlands    South Dakota  ﻿43.75°N 102.50°W  1978-11-10   \n",
       "BIBE        Big Bend           Texas  ﻿29.25°N 103.25°W  1944-06-12   \n",
       "\n",
       "          Acres                                        Description     1979  \\\n",
       "Code                                                                          \n",
       "ACAD   49076.63  Covering most of Mount Desert Island and other...  2787366   \n",
       "NPSA    8256.67  The southernmost national park is on three Sam...        0   \n",
       "ARCH   76678.98  This site features more than 2,000 natural san...   269840   \n",
       "BADL  242755.94  The Badlands are a collection of buttes, pinna...   858000   \n",
       "BIBE  801163.21  Named for the prominent bend in the Rio Grande...   282941   \n",
       "\n",
       "         1980     1981     1982  ...     2012     2013     2014     2015  \\\n",
       "Code                             ...                                       \n",
       "ACAD  2779666  2997972  3572114  ...  2431052  2254922  2563129  2811184   \n",
       "NPSA        0        0        0  ...    10440    17919    13953    13892   \n",
       "ARCH   290519   326508   339415  ...  1070577  1082866  1284767  1399247   \n",
       "BADL   952652  1175952  1030484  ...   883406   892372   868094   989354   \n",
       "BIBE   174008   167332   180144  ...   292055   316953   314102   381747   \n",
       "\n",
       "         2016     2017     2018     2019     2020     2021  \n",
       "Code                                                        \n",
       "ACAD  3303393  3509271  3537575  3437286  2669034  4054767  \n",
       "NPSA    28892    69468    28626    60006     4819     7284  \n",
       "ARCH  1585718  1539028  1663557  1659702  1238083  1750341  \n",
       "BADL   996263  1054325  1008942   970998   916932  1228481  \n",
       "BIBE   388290   440276   440091   463832   393907   524126  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum monthly visits into annual totals and merge the visit totals into the park-data dataframe\n",
    "park_annual_visits_df = park_visits_df.groupby(level=0).sum().transpose()\n",
    "park_data_df = park_data_df.join(park_annual_visits_df)\n",
    "park_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 50)\n",
      "                              Name Established  First Year\n",
      "Code                                                      \n",
      "NPSA                American Samoa  1988-10-31        1989\n",
      "BLCA  Black Canyon of the Gunnison  1999-10-21        2000\n",
      "CONG                      Congaree  2003-11-10        2004\n",
      "CUVA               Cuyahoga Valley  2000-10-11        2001\n",
      "DEVA                  Death Valley  1994-10-31        1995\n",
      "DRTO                  Dry Tortugas  1992-10-26        1993\n",
      "GAAR           Gates of the Arctic  1980-12-02        1981\n",
      "JEFF                  Gateway Arch  2018-02-22        2018\n",
      "GLBA                   Glacier Bay  1980-12-02        1981\n",
      "GRBA                   Great Basin  1986-10-27        1987\n",
      "GRSA              Great Sand Dunes  2004-09-24        2005\n",
      "INDU                 Indiana Dunes  2019-02-15        2019\n",
      "JOTR                   Joshua Tree  1994-10-31        1995\n",
      "KATM                        Katmai  1980-12-02        1981\n",
      "KEFJ                  Kenai Fjords  1980-12-02        1981\n",
      "KOVA                  Kobuk Valley  1980-12-02        1981\n",
      "LACL                    Lake Clark  1980-12-02        1981\n",
      "NERI               New River Gorge  2020-12-27        2021\n",
      "PINN                     Pinnacles  2013-01-10        2013\n",
      "SAGU                       Saguaro  1994-10-14        1995\n",
      "WHSA                   White Sands  2019-12-20        2020\n",
      "WRST            Wrangell–St. Elias  1980-12-02        1981\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the first year of a Park as their established year, if they were established betwen Jan-June; or the following year if they were established Jul-Dec.\n",
    "park_data_df['First Year'] = park_data_df['Established'].apply(lambda x: x.year if x.month <= 6 else x.year + 1)\n",
    "\n",
    "# Since we only have visit data from 1979 and beyond, we will filter out parks established prior to 1981.  \n",
    "# That will give us at least 2 years of visit data before the park became a National Park.\n",
    "park_data_filtered_df = park_data_df[park_data_df['First Year'] > 1980]\n",
    "print(park_data_filtered_df.shape)\n",
    "print(park_data_filtered_df[['Name', 'Established', 'First Year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12e770f971261f02467e136ae451d4f5bb6defd0f5ed675545d9d042537fc757"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('np': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
